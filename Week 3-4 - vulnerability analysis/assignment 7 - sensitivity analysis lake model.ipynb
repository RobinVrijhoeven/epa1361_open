{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lake model continued - sensitivity analysis\n",
    "\n",
    "In the previous week you used the lake problem as a means of getting acquainted with the workbench. In this assignment we will continue with the lake problem, focussing explicitly on using it for open exploration. You can use the second part of the [open exploration tutorial](https://emaworkbench.readthedocs.io/en/latest/indepth_tutorial/open-exploration.html) for help.\n",
    "\n",
    "**It is paramount that you are using the lake problem with 100 decision variables, rather than the one found on the website with the separate anthropogenic release decision**\n",
    "\n",
    "There is substantial support in the ema_workbench for global sensitivity. For this, the workbench relies on [SALib](https://salib.readthedocs.io/en/latest/) and feature scoring which is a machine learning alternative for global sensitivity analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SOBOL\n",
    "1. Apply Sobol with 3 separate release policies (0, 0.05, and 0.1) and analyse the results for each release policy separately focusing on the reliability objective. Do the sensitivities change depending on the release policy? Can you explain why or why not?\n",
    "\n",
    "*hint: you can use sobol sampling for the uncertainties, and set policies to a list with the 3 different release policies. Next, for the analysis using logical indexing on the experiment.policy column you can select the results for each separate release policy and apply sobol to each of the three separate release policies. If this sounds too complicated, just do it on each release policy separately.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T08:49:14.518174Z",
     "start_time": "2023-04-20T08:49:14.499760Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from ema_workbench import Samplers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ema_workbench import (Model, RealParameter, TimeSeriesOutcome, perform_experiments, ema_logging, ScalarOutcome, Policy, MultiprocessingEvaluator)\n",
    "\n",
    "from ema_workbench import Samplers\n",
    "\n",
    "from ema_workbench.analysis import feature_scoring\n",
    "from ema_workbench.analysis.scenario_discovery_util import RuleInductionType\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from SALib.analyze import sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "\n",
    "def lake_problem(\n",
    "        b=0.42,         # Decay parameter for P in lake (0.42 = irreversible)\n",
    "        q=2.0,          # Recycling exponent\n",
    "        mean=0.02,      # Mean of natural inflows\n",
    "        stdev=0.0017,   # Future utility discount rate\n",
    "        delta=0.98,     # Standard deviation of natural inflows\n",
    "        alpha=0.4,      # Utility from pollution\n",
    "        nsamples=100,   # Number of Monte Carlo samples to draw\n",
    "        steps=100,      # Number of time steps\n",
    "        l0=0, l1=0, l2=0, l3=0, l4=0, l5=0, l6=0, l7=0, l8=0, l9=0,\n",
    "        l10=0, l11=0, l12=0, l13=0, l14=0, l15=0, l16=0, l17=0, l18=0, l19=0,\n",
    "        l20=0, l21=0, l22=0, l23=0, l24=0, l25=0, l26=0, l27=0, l28=0, l29=0,\n",
    "        l30=0, l31=0, l32=0, l33=0, l34=0, l35=0, l36=0, l37=0, l38=0, l39=0,\n",
    "        l40=0, l41=0, l42=0, l43=0, l44=0, l45=0, l46=0, l47=0, l48=0, l49=0,\n",
    "        l50=0, l51=0, l52=0, l53=0, l54=0, l55=0, l56=0, l57=0, l58=0, l59=0,\n",
    "        l60=0, l61=0, l62=0, l63=0, l64=0, l65=0, l66=0, l67=0, l68=0, l69=0,\n",
    "        l70=0, l71=0, l72=0, l73=0, l74=0, l75=0, l76=0, l77=0, l78=0, l79=0,\n",
    "        l80=0, l81=0, l82=0, l83=0, l84=0, l85=0, l86=0, l87=0, l88=0, l89=0,\n",
    "        l90=0, l91=0, l92=0, l93=0, l94=0, l95=0, l96=0, l97=0, l98=0, l99=0):\n",
    "    # Create a NumPy array of the decision variables\n",
    "    decisions = np.array([l0, l1, l2, l3, l4, l5, l6, l7, l8, l9, l10, l11, l12, l13,\n",
    "                          l14, l15, l16, l17, l18, l19, l20, l21, l22, l23, l24, l25,\n",
    "                          l26, l27, l28, l29, l30, l31, l32, l33, l34, l35, l36, l37,\n",
    "                          l38, l39, l40, l41, l42, l43, l44, l45, l46, l47, l48, l49,\n",
    "                          l50, l51, l52, l53, l54, l55, l56, l57, l58, l59, l60, l61,\n",
    "                          l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73,\n",
    "                          l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85,\n",
    "                          l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97,\n",
    "                          l98, l99])\n",
    "    nvars = len(decisions)\n",
    "\n",
    "    # Calculate the critical pollution level (Pcrit)\n",
    "    Pcrit = brentq(lambda x: x ** q / (1 + x ** q) - b * x, 0.01, 1.5)\n",
    "\n",
    "    # Generate natural inflows using lognormal distribution\n",
    "    natural_inflows = np.random.lognormal(\n",
    "        mean=math.log(mean ** 2 / math.sqrt(stdev ** 2 + mean ** 2)),\n",
    "        sigma=math.sqrt(math.log(1.0 + stdev ** 2 / mean ** 2)),\n",
    "        size=(nsamples, nvars)\n",
    "    )\n",
    "\n",
    "    # Initialize the pollution level matrix X\n",
    "    X = np.zeros((nsamples, nvars))\n",
    "\n",
    "    # Loop through time to compute the pollution levels\n",
    "    for t in range(1, nvars):\n",
    "        X[:, t] = (1 - b) * X[:, t - 1] + (X[:, t - 1] ** q / (1 + X[:, t - 1] ** q)) + decisions[\n",
    "            t - 1] + natural_inflows[:, t - 1]\n",
    "\n",
    "    # Calculate the average daily pollution for each time step\n",
    "    average_daily_P = np.mean(X, axis=0)\n",
    "\n",
    "    # Calculate the reliability (probability of the pollution level being below Pcrit)\n",
    "    reliability = np.sum(X < Pcrit) / float(nsamples * nvars)\n",
    "\n",
    "    # Calculate the maximum pollution level (max_P)\n",
    "    max_P = np.max(average_daily_P)\n",
    "\n",
    "    # Calculate the utility by discounting the decisions using the discount factor (delta)\n",
    "    utility = np.sum(alpha * decisions * np.power(delta, np.arange(nvars)))\n",
    "\n",
    "    # Calculate the inertia (the fraction of time steps with changes larger than 0.02)\n",
    "    inertia = np.sum(np.abs(np.diff(decisions)) > 0.02) / float(nvars - 1)\n",
    "\n",
    "    return max_P, utility, inertia, reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model('Lakeproblem', function=lake_problem)\n",
    "\n",
    "model.uncertainties = model.uncertainties = [\n",
    "    RealParameter(\"b\", 0.1, 0.45),\n",
    "    RealParameter(\"q\", 2.0, 4.5),\n",
    "    RealParameter(\"mean\", 0.01, 0.05),\n",
    "    RealParameter(\"stdev\", 0.001, 0.005),\n",
    "    RealParameter(\"delta\", 0.93, 0.99),]\n",
    "\n",
    "levers = []\n",
    "for i in range(100):\n",
    "    levers.append(RealParameter(f\"l{i}\", 0, 0.1))\n",
    "    \n",
    "model.levers = levers \n",
    "\n",
    "model.outcomes = [\n",
    "    ScalarOutcome(\"max_P\"),\n",
    "    ScalarOutcome(\"utility\"),\n",
    "    ScalarOutcome(\"inertia\"),\n",
    "    ScalarOutcome(\"reliability\"),\n",
    "]\n",
    "policy = Policy(\"no release\", **{l.name:0 for l in model.levers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = 250*(2*5+2)\n",
    "with MultiprocessingEvaluator(model, n_processes=-1) as evaluator:\n",
    "    experiments, outcomes = evaluator.perform_experiments(scenarios, policy, uncertainty_sampling = Samplers.SOBOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_P': array([0.08122279, 0.06972903, 0.08141988, ..., 9.22394095, 9.34978365,\n",
       "        9.34886452]),\n",
       " 'utility': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " 'inertia': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " 'reliability': array([1.    , 1.    , 1.    , ..., 0.5508, 0.3562, 0.3548])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ST   ST_conf\n",
      "b      0.841812  0.042243\n",
      "delta  0.000039  0.000020\n",
      "mean   0.306484  0.033067\n",
      "q      0.313808  0.031281\n",
      "stdev  0.000203  0.000110\n",
      "             S1   S1_conf\n",
      "b      0.518634  0.056375\n",
      "delta  0.000042  0.000206\n",
      "mean   0.062771  0.026394\n",
      "q      0.088464  0.031965\n",
      "stdev  0.000342  0.001155\n",
      "                      S2   S2_conf\n",
      "(b, delta)      0.032809  0.078454\n",
      "(b, mean)       0.112312  0.086726\n",
      "(b, q)          0.080362  0.085449\n",
      "(b, stdev)      0.032964  0.078523\n",
      "(delta, mean)  -0.000097  0.000400\n",
      "(delta, q)     -0.000059  0.000394\n",
      "(delta, stdev) -0.000111  0.000374\n",
      "(mean, q)       0.028607  0.036998\n",
      "(mean, stdev)   0.017695  0.037420\n",
      "(q, stdev)     -0.004587  0.041042\n"
     ]
    }
   ],
   "source": [
    "y = outcomes[\"max_P\"]\n",
    "problem = get_SALib_problem(model.uncertainties)\n",
    "Si = sobol.analyze(problem, y, calc_second_order=True, print_to_console=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rvrij\\anaconda\\envs\\Model_based_decisions\\Lib\\site-packages\\scipy\\stats\\_qmc.py:763: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  sample = self._random(n, workers=workers)\n",
      "100%|████████████████████████████████████| 36000/36000 [06:16<00:00, 95.53it/s]\n"
     ]
    }
   ],
   "source": [
    "scenarios = 250*(2*5+2)\n",
    "policy = Policy(\"no release\", **{l.name:0.05 for l in model.levers})\n",
    "\n",
    "experiments2, outcomes2 = perform_experiments(model, scenarios, policy, uncertainty_sampling = Samplers.SOBOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = outcomes[\"max_P\"]\n",
    "problem = get_SALib_problem(model.uncertainties)\n",
    "Si = sobol.analyze(problem, y, calc_second_order=True, print_to_console=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = 250*(2*5+2)\n",
    "policy = Policy(\"no release\", **{l.name:0.1 for l in model.levers})\n",
    "\n",
    "experiments3, outcomes3 = perform_experiments(model, scenarios, policy, uncertainty_sampling = Samplers.SOBOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = outcomes[\"max_P\"]\n",
    "problem = get_SALib_problem(model.uncertainties)\n",
    "Si = sobol.analyze(problem, y, calc_second_order=True, print_to_console=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature scoring\n",
    "Repeat the above analysis for the 3 release policies but now with extra trees [feature scoring](https://emaworkbench.readthedocs.io/en/latest/ema_documentation/analysis/feature_scoring.html) and for all outcomes of interest. As a bonus, use the sobol experiment results as input for extra trees, and compare the results with those resulting from latin hypercube sampling.\n",
    "\n",
    "*hint: you can use [seaborn heatmaps](https://seaborn.pydata.org/generated/seaborn.heatmap.html) for a nice figure of the results. See also the [features scoring](https://emaworkbench.readthedocs.io/en/latest/indepth_tutorial/open-exploration.html#feature-scoring) section of the tutorial.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T08:49:14.520173Z",
     "start_time": "2023-04-20T08:49:14.503673Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from ema_workbench.analysis import feature_scoring\n",
    "from ema_workbench.analysis.feature_scoring import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x = pd.DataFrame(experiments) #turn into dataframe\n",
    "y = outcomes['max_P'] \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = feature_scoring.get_ex_feature_scores(x, y, mode=RuleInductionType.REGRESSION, nr_trees=100, max_features=0.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
